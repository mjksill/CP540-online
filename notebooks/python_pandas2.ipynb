{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Comparing Data and Dealing with Dates in Pandas\n",
        "\n",
        "Previously we have seen how to import simple data using `Pandas`.\n",
        "This worksheet will follow a similar trend, introducing other ways to\n",
        "manipulate the data we import, and show how it can recognize dates.\n",
        "\n",
        "We will use data from the website\n",
        "[GRIDWATCH](https://www.gridwatch.templar.co.uk/), which provides\n",
        "current and historical data on the UK's electrical grid.  This\n",
        "includes information on the demand, as well as a breakdown on the\n",
        "sources of the electricity (e.g., natural gas, solar, hydro, wind,\n",
        "etc.).\n",
        "\n",
        "Download the file \"gridwatch.csv\" by going to the [Myplace site for CP540](https://classes.myplace.strath.ac.uk/course/view.php?id=27428#section-5) or download the file directly by clicking [here](https://classes.myplace.strath.ac.uk/mod/resource/view.php?id=1758384). \n"
      ],
      "metadata": {
        "id": "42eJ2YW6nR6N"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7bzFK-bxeTF7"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        " \n",
        " \n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing data\n",
        "\n",
        "We can load the data in this CSV file into a Pandas dataframe in the same manner as we did in the previous notebook.  Let's put the data into the variable `df` and see the names of the columns.\n",
        "\n",
        " "
      ],
      "metadata": {
        "id": "btu3glao0Ect"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import io\n",
        " \n",
        "df = pd.read_csv(io.BytesIO(uploaded['gridwatch.csv'])) \n",
        "print(df.columns)\n"
      ],
      "metadata": {
        "id": "cH-yS2c6efbz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we look closely at the names of the columns, we will notice that many of them start with a space.  This is not necessarily a problem, as long as we remember to add this space when we call the columns; however, it is an inconvenience.  We can remove any leading space from the headers by adding a option to the function that reads the CSV file.\n",
        "\n"
      ],
      "metadata": {
        "id": "BriwUNYpTg4a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(io.BytesIO(uploaded['gridwatch.csv']), skipinitialspace=True)\n",
        "print(df.columns)"
      ],
      "metadata": {
        "id": "ICupYoCSTh90"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now those leading spaces have been eliminated.\n",
        "\n",
        "To see the contents of the dataframe, we print it."
      ],
      "metadata": {
        "id": "TUF9sYN1VLa_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df)"
      ],
      "metadata": {
        "id": "lww4E7VBVgt4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a larger file than we used last time, but it can easily be managed in the same way.  It contains data for around 7 days worth of energy generation, recorded at intervals of 5 minutes.  The resulting dataframe has 2016 rows and 25 columns of data.   \n",
        "\n",
        "Currently, the column of data under the heading \"timestamp\" is not recognized by Pandas as a time; it thinks that it is simply a string.  We can get Pandas to interpret this column of strings as times by using the `to_datetime` function:\n"
      ],
      "metadata": {
        "id": "GgjGBUyPsoaI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['timestamp'] = pd.to_datetime(df['timestamp'], format='%Y-%m-%d %H:%M:%S')  # Firstly we define the current timestamp in its current format\n",
        "print(df)"
      ],
      "metadata": {
        "id": "yT2Kw4rUz5Nk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plotting data\n",
        "\n",
        "Now we can begin to visualise the data. We can use a simple plot to see a comparison between the 3 types of energy generation. "
      ],
      "metadata": {
        "id": "Q6mO54dT14F7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pylab as plt\n",
        "\n",
        "plt.plot(df['timestamp'], df['wind'], label='wind')\n",
        "plt.plot(df['timestamp'], df['hydro'], label='hydro')\n",
        "plt.plot(df['timestamp'], df['solar'], label='solar')\n",
        "plt.xlabel('date')\n",
        "plt.ylabel('power / MW')\n",
        "plt.xticks(rotation=45)\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qXz7KaLDX2J-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Another way to plot the data is to use the plotting capabilities within Pandas."
      ],
      "metadata": {
        "id": "PR9LJz5lY1jO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import numpy as np\n",
        "#import matplotlib.pyplot as plt\n",
        "#import matplotlib.ticker as mticker\n",
        "\n",
        "\n",
        "df.plot(x=\"timestamp\", y=[\"wind\", \"hydro\", \"solar\"])\n",
        "plt.show()\n",
        "\n",
        "\n",
        "#help(plt.plot)"
      ],
      "metadata": {
        "id": "59BR_nkKepBP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Say for example now we want to see how much solar energy is generated each day. We can now use the new timestamp column we created to help us calculate the sum of energy for each day."
      ],
      "metadata": {
        "id": "MZWq3Kih2pbM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "\n",
        "#start = datetime.datetime.strptime(\"24-08-2022\", \"%d-%m-%Y\")                   # First, we define the first day in our dataframe \n",
        "#date_generated = pd.date_range(start, periods=8)                               # We can then create a range of dates from this, starting at the inital date stated \n",
        "                                                                               # and the following 7 days                     \n",
        "#dates = list(date_generated.strftime(\"%d-%m\"))                                 # We then turn this range into a list to allow us to utilise it\n",
        "date_list = pd.date_range(start='2022-08-21', end='2022-08-27')\n",
        "print(date_list)\n",
        "\n",
        "dailysolar = []                                                                # Here we create an empty list to collect the average solar energy for each day\n",
        "\n",
        "for date in date_list:\n",
        "  df_tmp = df[df['timestamp'].dt.date.between(date, date)]\n",
        "  dailysolar.append( df_tmp['solar'].sum() * 5.0/60.0 )                        # This makes use of the Boolean principles,\n",
        "                                                                               # and sums all the solar demands from each day, before depositing \n",
        "                                                                               # them in the avgsolar list\n",
        "print(dailysolar)\n",
        "\n",
        "plt.bar(date_list, dailysolar)                                                 # We can then visualise this in a bar graph.\n",
        "plt.xticks(rotation=45)                                                   \n",
        "plt.xlabel(\"Days\")\n",
        "plt.ylabel(\"Solar Energy Generation / MW h\")"
      ],
      "metadata": {
        "id": "hVRc45yAWNgh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also show the split of energy generation in a pie chart."
      ],
      "metadata": {
        "id": "gf-4l6rW6d6T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.pie(dailysolar, labels=date_list, labeldistance=1.15);\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "tnDGw9wSYbDf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can utilize another Python library, `plotly.express`, to show the data of all three types of energy. This import is interesting as it can be used to make interactive graphs. "
      ],
      "metadata": {
        "id": "qxRkJmqt7WmN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "\n",
        "fig = px.line(df, x = 'timestamp', y = ['hydro', 'wind', 'solar'],\n",
        "              labels={\n",
        "                     \"timestamp\": \"Day\",\n",
        "                     \"value\": \"Power Generated / MW\",\n",
        "                     \"variable\": \"Type of Energy\"\n",
        "                 })\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "dtCbr7SXjv0d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a simple graph, similar to the one shown previously in this worksheet, but using `plotly.express` allows us to hover over any data point on the graph and see its value.  This can be exapnded on to include filters to show only specific data on the graph, or show scatter graphs.  More information on this import can be found [here](https://plotly.com/python/line-charts/).\n",
        "\n",
        "\n",
        "Violin plots can be used to show the distribution of data in a dataset, so we can use them here to show how the average energy generated per day varies over the course of the week's worth of data we have. For these plots another python import is required - `seaborn`. The code used to generate these plots can be found [here](https://www.python-graph-gallery.com/violin-plot/). It is useful to note that this site contains many more different types of plots and the codes to create them. "
      ],
      "metadata": {
        "id": "LPZZmrPJ_ATG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Statistics\n",
        "\n",
        "To allow us to analyze these data on a day-by-day basis, it is helpful to create a categorize it according to the date, rather than by the time.  We create a new column in the dataframe with the date, which we create by using the function `dt.strftime`.  This function create a string which represents the date in the format we choose."
      ],
      "metadata": {
        "id": "lKsc3igFXe4x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['date'] = df['timestamp'].dt.strftime('%d-%m')                     \n",
        "print(df)                                                                   "
      ],
      "metadata": {
        "id": "ULA-MkYYWeop"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can observe the histogram of power generation from wind turbines throughout each day by using a violin plot."
      ],
      "metadata": {
        "id": "rTVXSYLEaCf9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        " \n",
        "ax = sns.violinplot(x=df[\"date\"], y=df[\"wind\"], palette=\"Pastel1\")\n",
        "\n",
        "ax.set_ylabel(\"Energy Generated (GW)\")\n",
        "ax.set_xlabel(\"Day\")\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jpKgQunPkMsB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ax = sns.violinplot(x=df[\"date\"], y=df[\"solar\"], palette=\"Pastel1\")\n",
        "ax.set_ylabel(\"Energy Generated / MW\")\n",
        "ax.set_xlabel(\"Day\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cSKrhii7UYRC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A note on the above graph - the plot can be seen to go into the negative range. However, there is no negative values in the dataframe. This can be explained by the fact there are values in the data close to or equal to 0. As violin plots use kernel distribution data, this processes the values of '0' in the data and gives a non-zero probability of finding a negative value in the data analysed. It does not mean however that there are negative values in the data. "
      ],
      "metadata": {
        "id": "eOghn9Tugoxr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ax = sns.violinplot(x=df[\"date\"], y=df[\"hydro\"], palette=\"Pastel1\")\n",
        "ax.set_ylabel(\"Energy Generated / MW\")\n",
        "ax.set_xlabel(\"Day\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3j1fbkXbUb7y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Conclusion\n",
        "\n",
        "In this worksheet we have seen different type of plots available to us in python using different modules, and how they can be created with pandas dataframes. We have also seen how date values within dataframes can be edited and manipulated to allow us to view data more clearly. "
      ],
      "metadata": {
        "id": "UEnoRw38HzEP"
      }
    }
  ]
}