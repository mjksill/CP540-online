{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1mNz9lxhxXrDRLWeyo91E6ogAMHhprg_7","timestamp":1694030263367}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"view-in-github"},"source":["<a href=\"https://colab.research.google.com/github/mjksill/CP540-online/blob/main/notebooks/Pandas_4_Interpreting_Solar_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"markdown","source":["# Filtering and exploring data with Pandas\n","\n","\n","This worksheet will focus on uploading data from a csv file into Google Colab, and analysing it.\n","First, we import the file we require - in this case it is data on solar radiation collected from a surface station.\n","Download the data by going to the [Myplace site for CP540](https://classes.myplace.strath.ac.uk/course/view.php?id=27428#section-5) or download the file directly by clicking [here](https://classes.myplace.strath.ac.uk/mod/resource/view.php?id=1767366).\n"],"metadata":{"id":"4Mhmq7cOT9vy"}},{"cell_type":"code","source":["from google.colab import files\n","\n","\n","uploaded = files.upload()"],"metadata":{"id":"T_mi_1m5T9h3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Then we import the data to a dataframe."],"metadata":{"id":"Ni0XPOtMWHKw"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"FGzq1AqUT6Hn"},"outputs":[],"source":["import pandas as pd\n","import io\n","\n","df = pd.read_csv(io.BytesIO(uploaded['midas-open_uk-radiation-obs_dv-202107_lanarkshire_00987_drumalbin_qcv-1_1995.csv']),\n","                skipinitialspace=True)\n","\n","print(df)"]},{"cell_type":"markdown","source":["As we can see there are quite a few columns that we don't require, and also a lot of inital rows we don't need. By looking at the csv file we can see the first 74 rows aren't important, so we can skip these when setting up the dataframe using the following command."],"metadata":{"id":"P_fkPPT7WF-K"}},{"cell_type":"code","source":["df = pd.read_csv(io.BytesIO(uploaded['midas-open_uk-radiation-obs_dv-202107_lanarkshire_00987_drumalbin_qcv-1_1995.csv']),\n","\n","                skiprows=[*range(75)], skipinitialspace=True)\n","\n","print(df)"],"metadata":{"id":"t6-HO-vpWrBb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Now to get rid of the columns we don't need, we can remove them using their column indexes. We can also remove the bottom row of data as it is blank.\n","\n","From looking at the data we can see that there are measurements every hour, but at the end of each day there is also a cumulative measurement. Lets remove all the hourly data, and focus on the 24 hour daily data.\n","\n","We can also see there is timestamps on each row of data in the 'ob_end_time' column. To ensure this is recognised as a time and date, we must define it as such. Once this is done, we can also create a new column containing the date for each row of data, but in a different format.\n","\n","Once this is complete, we can then plot the data to visualise it."],"metadata":{"id":"1P8MqhySXJlK"}},{"cell_type":"code","source":["df = df.drop(df.columns[[1, 2, 4, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]], axis=1)        # Drop unrequiured columns\n","df = df.drop([8447], axis = 0)                                                # Drop bottom row of data\n","\n","df = df[df.ob_hour_count != 1]                                                # Remove all rows that contain data collected hourly\n","\n","import pylab as plt\n","import datetime as datetime\n","\n","df['ob_end_time'] = pd.to_datetime(df.ob_end_time, format='%d/%m/%Y %H:%M')   # Define the 'ob_end_time' column as a date and time\n","df['timestamp'] = df['ob_end_time'].dt.strftime('%m/%Y')                      # Create a new column showing the date in a different format\n","\n","df.dropna()                                                                   # This just drops any rows which contain no data\n","\n","print(df)\n","\n","df = df.sort_values('ob_end_time', ascending=True)                            # This just confirms the data is sorted in the correct order\n","plt.plot(df['ob_end_time'], df['glbl_irad_amt_q'])                            # Plot the solar irradiation against time/date"],"metadata":{"id":"RBbQyfGNYjp6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["From the graph we see that it looks like there is data missing from between July and September. We will come back to this later.\n","\n","We can caculate the mean solar irradiation for each month and plot this to see how it varies over the year."],"metadata":{"id":"3hUXd3hkdAuN"}},{"cell_type":"code","source":["import datetime\n","import numpy as np\n","\n","months = pd.date_range('1995-01-01','1995-12-31',                             # This creates a list of the months we have data for - January to Decemeber 1995\n","              freq='MS').strftime(\"%m/%Y\").tolist()\n","print(months)\n","\n","avgq = []                                                                     # We then create an empty list to store the average data\n","for i in months:                                                              # Using a for loop we can then loop through each month, and pandas will give us the\n","    avgq.append((df.loc[df['timestamp'] == i, 'glbl_irad_amt_q'].mean()))     # mean of the solar irradiation\n","\n","print(avgq)\n","\n","plt.plot(months, avgq)\n","plt.xticks(rotation=90)\n","plt.show()"],"metadata":{"id":"4qzekdYv0bHx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["A density plot could also be used to show how the solar irradiation collected is distributed."],"metadata":{"id":"YR0z9RJei7dq"}},{"cell_type":"code","source":["# library & dataset\n","import seaborn as sns\n","\n","# plot\n","sns.kdeplot(df['glbl_irad_amt_q'])"],"metadata":{"id":"NbqGYr4WdT7y"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Now to return to the missing data - lets use some plots we've seen previously."],"metadata":{"id":"Ow1QN1TaYhuB"}},{"cell_type":"code","source":["import plotly.express as px\n","\n","fig1 = px.line(df, x = 'ob_end_time', y = 'glbl_irad_amt_q')\n","\n","fig1.show()"],"metadata":{"id":"EDdlm9mMkWmv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n","x = df['ob_end_time'].tolist()\n","y = df['glbl_irad_amt_q'].tolist()\n","\n","\n","plt.bar(x, y)\n"],"metadata":{"id":"jI0gpHoHld7z"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We can clearly see by extracting the daily results from the dataframe, that there is no daily 24 hour data for most of July and August. This may be due to an error in recording the data at the end of each day, so needs investigated further.\n","\n","We can try filtering the original data by removing the data for every 24 hours, and instead use the hourly data to analyse. To do this, we can create a new dataframe to manipulate. We need to give it a new name, in this case 'df1', but apart from that we can copy the code we used previously."],"metadata":{"id":"rlV9srE48SAw"}},{"cell_type":"code","source":["df1 = pd.read_csv(io.BytesIO(uploaded['midas-open_uk-radiation-obs_dv-202107_lanarkshire_00987_drumalbin_qcv-1_1995.csv']),\n","\n","                skiprows=[*range(75)], skipinitialspace=True)\n","\n","df1 = df1.drop(df1.columns[[1, 2, 4, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]], axis=1)\n","df1 = df1.drop([8447], axis = 0)\n","\n","df1 = df1[df1.ob_hour_count != 24]\n","\n","df1['ob_end_time'] = pd.to_datetime(df1.ob_end_time, format='%d/%m/%Y %H:%M')\n","df1['timestamp'] = df1['ob_end_time'].dt.strftime('%Y-%m-%d')\n","\n","print(df1)\n","\n","df1 = df1.sort_values('ob_end_time', ascending=True)\n","plt.plot(df1['ob_end_time'], df1['glbl_irad_amt_q'])"],"metadata":{"id":"rjTQKAcO8e-B"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Judging by this set of the data, there was clearly an issue in those time periods recording data in general.\n","\n","Nonetheless, we can still find and plot the average solar irradiation for each day of the year we have data for, and this can be done using code we have previously used, with some small tweaks."],"metadata":{"id":"9Xi7a_t2mWhC"}},{"cell_type":"code","source":["days = pd.date_range('1995-01-01','1995-12-31',                               # Instead of months, we create a list of days for the year\n","              freq='D').strftime(\"%Y-%m-%d\").tolist()\n","#print(days)\n","\n","dailyavgq = []\n","for i in days:\n","    dailyavgq.append((df1.loc[df1['timestamp'] == i, 'glbl_irad_amt_q'].mean()))\n","\n","#print(dailyavgq)\n","\n","plt.plot(days, dailyavgq)"],"metadata":{"id":"0kKWvS1U-D9t"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["So here we have the irradiation for each day, however the x-axis label is very messy - this is due to all the days of the year being using as x-ticks. To correct this, we can create a third dataframe."],"metadata":{"id":"92e5IEZjoAGw"}},{"cell_type":"code","source":["df2 = pd.DataFrame({'days':days,                                              # Create the new dataframe and define the columns and their data\n","                    'dailyavgq' : dailyavgq})\n","print (df2)\n","\n","df2['days'] = pd.to_datetime(df2.days, format='%Y-%m-%d')                     # Define the date format for the days column\n","\n","plt.plot(df2['days'], df2['dailyavgq'])"],"metadata":{"id":"7g_5gzUsOYfE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["That's a lot more tidier. If we wanted to we could filter the data to find out the exact dates where we have no data, but we can also use the `plotly.express` interactive graph to see this more clearly."],"metadata":{"id":"AIu1o4y2QLRl"}},{"cell_type":"code","source":["import plotly.express as px\n","\n","fig = px.line(df2, x = 'days', y = 'dailyavgq')\n","\n","fig.show()"],"metadata":{"id":"NJKhxieNTuVk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Using this we can pinpoint the days that there were no data recorded. We also notice there are other days throughout the year where no data was recorded."],"metadata":{"id":"L88KuHMoorWu"}},{"cell_type":"markdown","source":["### Conclusion\n","\n","We've seen in this worksheet once again how to manipulate data in a dataframe, and how to use code we have previously wrote, and tweak it to be useful in other circumstances."],"metadata":{"id":"gvWnt-sQqxlU"}}]}